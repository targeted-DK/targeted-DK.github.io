---
layout: post
title: "Scheduling-Context Capabilities"
date: 2024-12-24
categories: Systems Scheduling
---

# Scheduling-Context Capabilities


# Introduction

Cyber-physical 시스템은 강력한 termporal requirements를 가지고 있는데 이는 OS에서 지원되지 않는 부분이다. OS의 경우 우선도와 시간 민감도, 중요성을 융합한다.
사용되는 분야에 따라 temporal protection이 필요하다. 
AAV야 말로 mixed-criticality system(MCS)의 예시이다. 이는 공간, 무게, 전력을 줄여야한다는 비행학의 개념이다. safety-critical 시스템에서는 어떤 component의 작업 수행이 덜 중요한 component로부터 영향 받지 않아야 한다. 
시스템은 결국 공간 및 시간적으로 직교하여 분리되어 있다.

Integrity property는 데드라인은 반드시 준수되어야 한다는 규칙이다. Worst-case execution time(WCET)이 수행될 수 있는 시간이 항상 존재하여야 함. 
스케쥴 분석에 따르면 overcommitted system이란 모든 것들이 항상 스케쥴 되지 않을 수 있다는 것이다.
MCS의 경우 시간적 분리를 위한 OS 지원이 필요하며 이는 상위 우선도(낮은 임계) 스레드가 높은 임계 스래드를 preempt할 수 있지만 프로세서 전체를 독점할 수는 없다. 
그래서 이 논문에서는 다음을 다룬다.
1. capability 시스템은 낮은 overhead를 발생시킨다.
2. cpu-time 한도라는 개념은 빠른 ipc 도입을 위해 호환이되며 이는 전통적으로 고성능 microkernels에 사용된다. 그리고 실시간 자원 공유 정책과 호환이 가능하다.
3. preempt가 불가능한 seL4 microkernel에 대한 설명과 사용자 레벨에서 커널 메모리는 다룰 수 있는 커널 모델에 대한 설명. 이는 강력한 공간 분리를 위해 사용됨
4. 커널의 static policies위에 사용자 레벨 스케쥴러 안에 동적 우선도 시스템을 도입함. 이는 임의의 스케쥴링 정책이 적은 overhead로 도입될 수 있음을 보여줌.


# Background
## Real Time Theory Basics
표준 실시간 이론은 task라는 용어를 사용하는데 이는 OS의 스레드라는 개념을 매핑한다. 이는 주기적으로 스레들을 실행하는 것을 의미하는데, 이는 일반적은 통제 시스템에 매핑됨을 의미한다.
비주기성 스레드는 최소 도달 시간이라는 개념을 장착한 모델을 사용하여 간섭 한도를 최대화하고 이는 스레드의 주기동안 스케쥴 분석에 사용된다. RT(실시간) 이론은 데드라인이 있으며 이는 반드시 연산이 끝나야하는 시간이며 이는
explicit 또는 implicit할 수 있다.
우선도는 고정이거나 동적일 수 있다. 가장 합당한 고정 방식은 rate-monotonic priority assignment(RMPA)이며 이는 주기의 역인 rate가 우선도가 된다. Total utilization이 log2이하일 경우 스케쥴성을 보장할 수 있다. 
가장 합당한 정책은 earlist-deadline first(EDF)이며 이는 동적 우선도 정책으로 가장 데드라인이 가까운 스레드를 선택한다. 
스케쥴 한도를 넘는 건 overcommited / overloaded된다고 표현한다. 

## Criticality, time-sensitivity and trust
Criticality는 전체 시스템 목적에 근거하여 각 component의 중요성을 의미한다. 
Time sensitivity의 경우 스레드가 특정 시간에 프로세서에 접근하기 위해 얼마나 중요한지를 의미한다.
Trust의 경우 어떤 component가 올바르게 작동하기 위해 필요한 의존성을 의미한다. 

## Capabilities to time
Capabilites는 공간적 자원의 접근 통제권에 대해 미세하게 조정된 방식이다. 
시간의 경우 임의로 나눌수 있지만 변화시킬수 없다. 시간에 대한 capabilities는 공간 자원과는 달리 다르게 사용된다. 이는 hierarchial delegation을 손실 없이 지언할수 없고 또한 가상화 시킬수 없다. 양도가 공간 기능의 좋은 이점이지만 그렇다고 양도가 성격을 규정하지 않으며 이는 prima facie evidence of access privilege임을 알 수 있다. 

## Resource Sharing
주요 요소들의 integrity는 스레드 간의 통신에 매우 중요하다. 가장 기본적인 방법은 공유 데이터와 코드를 캡슐화하여 싱글 스레드 리소스 서버변화시키는 것이다. 만약 공유 서버가 다른 우선도를 가진 여러 클라이언트가 접근한다며 이는 priority inversion을 초래할 수 있다. 예를 들어 낮은 우선도 스레드가 높은 우선도 스레드를 막는 경우 이다. 그래서 보통 우선도의 스레드가 프로세서를 독점하고 낮은 우선도 스레드가 중요 부분을 들고 있다면 영구적인 priority inversion이 발생할 수 있다.
실시간 시스템의 상호 배제에 대해 일반적인 접근법은, non-preemptive critical sections(NCP)를 포함하거나, immediate and original priority ceiling protocols(IPCP and OPCP)를 포함한다. 실시간 시스템에 관련해서 상호 배제에 관련한 가장 중요한 점은 priority inversion(우선도 역전)에 대한 기준이다. 이러한 시스템은 기본적으로 안정성에 우선을 두기 때문에, 기능의 복잡도 또한 매우 중요하다. 효율적인 시스템은 performance overhead가 주안점이지만, secure system의 경우엔 은닉된 채널을 피하는 것이다.

![](/images/Scc/1.png)

위 사진은 4개의 다른 프로토콜을 비교한다. 각각 장단점이 존재한다. PIP의 경우 매우 높은 기능 복잡도를 가지고 있으며 blocking time이 높아 resource ordering이 사용되지 않는다면 deadlock 현상을 만들지만 간단한 것이 장점이다. NCP의 경우 가장 간단하지만 가장 긴 blocking time을 가지고 있다. IPCP의 경우 간단하지만 모든 자물쇠의 우선도를 미리 알고 있어야 한다. OPCP의 경우 가장 짧은 BLOCKING TIME을 가지고 있지만 PIP보다 더 복잡하며, 모든 자물쇠가 GLOBAL STATE를 알 수 있도록 유지해야한다. 이 경우 이 논문의 목적과는 맞지 않는데, 이는 covert channel을 만들고 sel4의 탈중앙화된 사용자 레벨 자원 관리와 호환되지 않기 때문이다. IPCP의 경우 커널이 critical section에 대한 지식 없이 완성될 수 있음을 다음 섹션에서 보여 줄 것이다. 

# MCS Scheduling Model
## Requirements
이 부분에서 mixed-criticality scheduling 모델을 설명할 것이며, 이는 seL4와 같은 높은 안정성 시스템에 적합하다. 모델은 다음 기준을 만족해야 한다.

### Capability-controlled enforcement of time limits :
Capabilities는 접근 권한에 대해서 생각할 수 있도록 도와준다. 이는 seL4와 같은 capability-based spatial access control of security-oritented system와 문제 없이 결합이 가능토록 한다.

### Policy Freedom : 
microkernel의 철학을 따라, 이 모델은 시스템들이 특정 리소스 관리 정책을 따르도록 강요하지 않는다. 이 모델은 넓은 범위의 scheduling policy, resource-sharing models, locking protocols를 지원한다.

### Efficient : 
모델은 가장 좋은 implementation을 가장 적은 overhead를 사용해야 한다. 예를 들어, 고성능 마이크로 커널의 빠른 메세지 전송 IPC와 호환되어야 한다.

### Temporal Isolation : 
시스템 설계자들이 시스템을 만들때 한 부분의 에러가 다른 시스템 부분의 에러와 연결되지 않도록 해야한다. 이는 공유 자원에도 적용된다.

모델은 가장 기본적인 커널 레벨에서 isolation을 제공하면서도 사용자 레벨에서 복잡한 스케줄 정책이 도입될 수 있도록 해야한다. 이 논문에서는 캐시와 가상 메모리를 가지고 있는 현대화된 멀티코어 하드웨어을 대상으로, 가장 비관적인 WCET의 기능을 exploit 하도록함.

## High-Level Concepts

정의에 따르면, priority(우선도)는 작동가능한 스레드에서 다음 가장 높은 우선도를 선택한다. MCS를 지원하기 위해서 우선도의 정의를 바꾸지 않지만 스레드가 runnable(작동가능한)하다는 의미를 바꾸려고한다. 이는 각 스레드에 사용되는 budget(한도)를 사용하여, 만약 스레드가 한도를 소진하였을 경우
작동 불가능한(non-runnable) 상태로 바꾼다. 우리는 static priority model를 사용하며(커널은 우선도를 마음대로 조정하지 않지만 시스템 콜을 통해서는 바뀔수 있음), 이를 유저 레벨에서 동적 우선도를 도입할 수 있도록하여 특정 스케줄 모델의 클래스만 제한하는 것 최대한 피하려고한다.

### Budgets and Scheduling contexts
Scheduling context(SC)의 가장 근간에는 시간 할당의 기본적인 추상화가  존재한다. SC는 object-cpability 시스템의 시간을 표현하며 이는 SC가 스레드나 주소  공간 또는 통신 종점(포트)와 같은 first-class에 해당함을 의미한다. SC는 'capability to a scheduling context object(scCap)이라고 표현할 수 있다.
scCap은 프로세서에 대한 접근 특권을 의미하고, 이는 capability to time(시간에 대한 능력)을 의미한다. 스레드가 작동하기 위해서는 scCap이 필요하며 이는 스레드가 소비할 수 있는 CPU 대역폭의 최대치를 의미한다.
실시간 시스템의 변할 수 있는 특징은 대역폭 제한은 특정 시간대에 도입되어야 한다는 점이다. 이를 도입하기 위해서 SC는 period(주기)를 T로 표현하며, budget(한도)를 C로 표현한다. 이 두 변수는 C <= T의 관계를 가지며 이는 SC가 주어진 주기(시간)내에서 소비할 수 있는 최대한의 시간이 된다. 그래서 U (utilization) 가동률률 U = C/T로 표현하며 이는 최대 CPU 가동률이 된다. SC는 많은 시스템에 사용되는 시간 조각의 일반화된 개념이라고 볼 수 있다.
멀티 코어 시스템에서는 SC가 특정 코어에 대한 접근 권한을 의미한다. load balancing과 같은 core migration는 커널이 아닌 사용자 레벨에서 도입되어야할 정책이다. 스레드는 보유한 SC를 다른 코어의 SC로 교체함으로써 이동이 완료된다.
한도를 정하는 것은 admission control(진입 제어)이며 이는 적절한 권한이 필요하다. 각 코어에 주어진 총 시간은 코어당 scheduling-control capability(sched_control)로 표현한다.

### Priorities
Fiasco.OC는 L4 microkernel에 스케줄링을 도입하였다. 이는 개념적으로 우리와 비슷하지만, Fiasco.OC의 SC는 capability-controlled가 아니다. 또한 Fiasco.OC는 priority(우선도)를 SC의 속성으로 사용한다. 반대로 우리는 priority가 스레드의 속성이 된다. 이의 장점은 priority와 SC가 직교적인 관계를 띄가 된다.
Fiasco.OC 처럼 우리는 우선도를 static attribute(고정된 속성)으로 사용한다. (다만, 사용자 레벨에서 시스템 콜을 사용하여 변경시킬 수는 있다.) 그 이유로는 첫번째로 고정 우선도 스케줄링은 이미 산업계에 많이 친숙하고 널리 사용되는 개념이기 때문이다(그래서 인지 EDF는 종종 눈치를 받곤 한다). 또한 seL4에 사용된 모델들에 잘 적용되며 시간 조각 속성을 scCap을 대신하여 교체할 수 있다. 또한 이 모델의 한개의 우선도를 사용하여 EDF의 동적 우선도를 사용할 수 있다(낮은 오버헤드로도 가능). 하지만 반대는 참이 되지 않는다. EDF의 동적 우선도를 고정 우선도로 매핑하는것은 단순하지 않으며 이는 높은 오버헤드를 발생시킨다. 커널이 고정 우선도 스케줄과 같은 특정 정책을 도입한다면 우리의 접근방식은 다른 정책들을 효율적으로 도입할 자유를 보장한다. 
마지막 이유로는 고정 우선도가 overcommited system에 대한 행동 방식에 대한 추론할 수 있는 능력을 제공한다. Overcommitting은 모든 SC의 가동률의 합이 스케줄 한계점 이상이 되는 것을 의미하는데, 이는 critical hard 실시간 스레드에는 큰 시간 버퍼가 필요하기 때문이다. 또한 커널이 policy-free하기 위해 중요하다. 특정 시스템의 정책은 overcommitment의 정도와 특징에 따라 달려있다. 예를 들어 high 스레드의 RMS 스케줄 능력을 69퍼센트로 제한하면서도 low 스레드는 overcommit 할 수 있게 하여 overcommitment의 정도는 hard RT와 soft RT와 best-effort 스레드에 따라 달라질 수 있다. 그런 정책은 커널 보다 사용자 레벨에서 도입되어야 할 것이다. 

overcommitting의 결과는 EDF 기반 시스템에서는 예측하기 힘들며 그렇기 때문에 시스템 자체로도 분석하기 힘들어진다. 반대로 고정 우선도의 결과는 이해하기 쉽다. 만약 P 이상의 우선도를 가진 스레드들의 모든 가동률의 합이 가동률 상한치보다 낮다면, 모든 스레드는 기한을 맞출 수 있으며 우선도 P보다 낮은 값을 가진 스레드는 기한을 못 맞출 수도 있다. 이는 스케줄을 쉽게 분석할 수 있도록한다.

## Criticality
우리는 criticality의 변화를 지원하기 위해 커널을 건드리지 않는다. 이는 사용자 레벨에서 이뤄져야 한다.(사용자 레벨에서 sched_control capability를 가지고 있어야 한다.) 커널은 우선도를 자체적으로 건드리지 않을 것이다. switch에 대한 필요성을 알려면 critical 스레드에게 가장 긍정적인 execution time bound를 제공하는 것이다. 이는 일반적인 작업에 충분하고 높은 가동률을 가진다. 만약 어떤 예외적인 상황에서 CRITICAL 스레드가 이 한도를 초과해야한다면 더 큰 한도가 주어질 것이며 CRITICALITY(임계성)이 증가되어 높은 우선도와 낮은 임계점을 가진 스레드의 방해를 받지 않을 것이다. 


## Mechanics
### Replenishment
가득 찬 SC를 가진 스레드 경우, C = T일 때, 더 높은 우선도 스레드에서 남은 CPU 대역폭을 독점할 수 있다. 이는 best-effort 스레드가 여유(slack)시간 작동할 때 유용하다. 신뢰받는 critical 스레드가 응급 상활을 제외하고 CPU의 작은 부분 이상 사용이 금지되어 있을 때도 유용하다. 가득 찬 한도를 가진 스레드는 preemption rate 1/T 이외에는 오버헤드를 일으키지 않는다. 
부분 적으로 SC를 가진 스레드의 경우, C < T 일 때는 작동하지 않는데, 이는 다시 채워지기 전까지 모든 한도를 다 소진하였기 때문이다. 다시 보충(replenishment)을 위해서는 sporadic servers model을 이용한다. Sporadic server는 슬라이딩 윈도우(sliding window)를 사용하는데 이는 주기를 초과하지 않는 시간 간격에서 C이상 소비하지 않음을 의미한다. 이는 스레드가 주기 마지막까지 한도를 저장해두는 것을 방지하고 C를 넘어서 작동하는 것을 방지한다. 이는 남은 한도를 계속 추적하여 시간 t에 스레드가 prempted되는 경우 보충 스케쥴을 시간 t + T로 잡는다.
실제로는 무한한 보충 횟수를 추적할 수 없기 때문에 이 부분을 도입할 시에는 queued 보충이 한계점을 초과할 때 초과 한도는 버려진다. 만약 한계점이 1이라면, the behaviour degrades to polling servers, 사용되지 않는 한도는 잃어버려지며 스레드는 다음 주기 때 까지 작동할 수가 없어진다. 
적정한 보충 값은 시스템에 따라 달라지며 또한 하드웨어에 따라 달라진다. 그렇기 때문에 threshold 또한 SC의 속성이 된다. SC의 크기는 변할 수 있기 때문에 시스템 설계자들이 이 한계를 SC마다 다르게 설정할 수 있다. 
한도가 만료될 때 보충이 준비된다면, 스레드는 당장 실행이 가능하다. 가진 우선도에 따라 ready queue 끝에 추가되는데 이는 우선도 내에서도 작동하는 스레드의 스케줄을 정하는 것은 round-robin이다. 


### Budget overrun
스레드는 여러가지 이유로 한도를 소진시킬 수 있다. 한도는 속도가 제한된 최선 스레드에 사용되며, 이 경우 한도 오버런(budget overrun)은 일반적인 시간 조각 reemption 최선 시스템과 다르지 않다. 한도는 신뢰할수 없는 스레드가 선언된 WCET을 따르도록 강제한다. 그렇다면 오버런은 계약 위반이며, 이는 스레드나 하위 시스템 재시작의 이유가 될 수 있다. 마지막으로 critical 스레드의 오버런은 긴급상황을 의미할 수 있다. 예를 들어, critical 스레드는 넉넉한(optimistic) 한도로 스케줄이 될 수 있으며 이는 less critical 스레드보다 더 나은 서비스를 제공하며, 이러한 스레드의 오버런은 긴급 한도의 필요성을 의미할 수 있다.
오버런을 다루는 것은 시스템 마다 다르며, 커널의 경우엔 필요한 정책을 도입하는데 필요한 장비는 제공하는데 사용되어야 한다. 여기서 가장 중요한 장치는 timeout exception(시간 만료)이며, 이는 스레드가 preempted 되었을 때 발생한다. 시스템이 예외를 다루기 위해서는 각 스레드가 선택적으로(optionally) timeout exception handler와 관련되어야하며, 이는 시간적으로 (공간적) 보호 예외 취급과 동일하다. 스레드가 preempted되는 경우 , 커널은 취급자(handler)에게 IPC 메세지를 통해 통보한다. 만약 스레드가 시간 만료 취급자가 없다면 예외는 무시된다.
취급자는 오버런 정책에 대한 여러가지 선택이 있는데, 1. 1회성 긴급 한도를 스레드에 제공하여 계속 지속하게 하거나 2. 영구적으로 스레드 SC의 한도를 증가하거나, 3. 시스템의 criticality를 less critical threats의 우선도를 낮추어 변화시키거나 4. 스레드를 kill / suspend하는 경우나, 5. 마지막으로 요청을 포기하고 서비를 롤백 시키는 것이다. 당연하게도 이런 부분들은 취급자가 충분한 권한을 가지고 있다는 가정하에 이루어진다. (한도 관련해서는 sched_control)

## Resource sharing
캡슐화된 공동 자원에 접근하는 것은 cross-address space IPC가 필요하다. invocation cost(발동 비용)를 최소화하기 위해서 스케줄러 발동은 IPC 간에는 삼가하는것이 중요하다. 이는 역사적으로 L4 microkernels들이 담당해 왔따. 스케줄러를 우회하지 않는 것이 대부분의 IPC가 L4 kernel IPC보다 느린이유이며, 이는 CertiKOS의 경우 4배에 달한다.
과거 L4 커널의 경우 시간 조각을 기부하는 형식으로 스케줄러 사용을 피해왔다. 이는 서버가 client의 시간 조각을 사용할 수 있었다. 이는 매우 빠른 방법이지만, 원칙이 존재하지 않고 어려우며, 분석하기 어려운 형태였다. 예를 들어, 시간조각은 서버가 실행되는 동안 만료될 수 잇으며, 이후에는 서버가 자신의 서버 자신의 시간 조각을 사용한다. 서버의 실행 시간은 지속적으로 관리되는 부분이 아니며, 또한 여기에는 시간적 독립이 적용되지 않는다.
우리의 모델은 공유 서버를 지원하며 이는 스케쥴러의 우회를 포함하는데 이는 scheduling-context donation을 원칙적으로 사용한다. 서버를 부르는 client의 경우 SC를 전달할 수 있으며 서버는 client의 SC에 요청에 응답할때까지 실행할 수 있다. 이는 서버가 소비하는 시간을 작업을 요청한 클라이언트에 청구하도록 한다.
이런 공유서버는 수동적으로 도입되며, 이는 서버가 자체적으로 SC를 보유하고 있지 않기에 runnable하지 않으며, 클라이언트의 SC를 빌려 사용해야 한다. 반대로 활성화된 서버의 경우 자체적인 SC를 보유하고 있으며 이는 client 기준에서는 무료로 실행하는 것처럼 보인다. 이 모델은 두가지 방법을 모두 지원하는데, 이는 모든 시스템이 엄격한 시간적 분리를 요구하지 않기 때문이다.
수동적 서버의 경우 효과적으로 migrating-thread 모델을 제공하면서도 커널이 스택을 관리하지 않아야 한다. 또한 간단하고 무료로 IPCP 도입을 지원한다. 이 서버는 모든 clients들에게 우선도의 상단을 제공하며, 모든 client의 실행을 atomic하게 만든다. 이는 SC를 우선도로 부터 분리시켜서 가능하다. IPCP의 주요 단점은 모든 locker들의 우선도를 미리 알고 있어야하며, 이는 capability-based system을 enforce할 수 있도록 한다. 서버는 적절한 invocation capability를 통해서만 접근이 가능하며 이는 시스템 설계자가 그러한 capability가 우선도를 알거나 통제하고 있는 스레드를 통해 가능하도록 해야한다.
다음 사진에서는 이 페이퍼 초기에 논의된 AVV의 간소화된 설계이다. 여러개의 수동 구조가 있으며 이는 캡슐화된 공유 데이터 구조이며 transaction semantics가 필요하다. 대부분의 통신은 RPC 타입의 메세지 전달로 이루어진다. 기기 드라이버가 IO 완료를 Notification(점선 화살표)를 통해 알려주며 이는 공유 메모리 버퍼를 사용한다.

## Timeout exceptions
만약 수동 서버가 한도를 다 소진한다면 서버와 기다리는 clients들은 한도가 다시 보충될 때까지 차단된다. 이는 client가 서버를 신뢰할 수 있어야하면서도 모든 서버의 다른 clients들도 그래야만 한다. 이 경우, 다른 criticality(임계점)을 가진 client들간의 서버 공유를 금지시켜야한다.
타임아웃 만료의 경우 이러한 신뢰의 필욧어을 제거해주며 다름 임계점을 가지더라도 서버를 공유할 수 있도록 해준다. 서버의 타임아웃 취급자는 여러 선택지를 사용할 수 있다. 한도가 부족한 서버의 경우 client로 프로토콜 위반을 제시하며 이는 client를 포기함으로써 페널티를 부과할 수 있다. 이 선택지는 매력적인데, 이는 오버런에 사용될 수 있는 한도를 최소화하기 때문이다.
반대로 helping schemes와 같이, Fiasco.OC에 도입된된 PIP나 대역폭 상속같은 경우 대기 client가 다른 client의 계약 위반에 대해 납부하도록 한다. 이는 시간적 격리를 약화시키며 또한 서버의 필요 예비 한도가 full WCET와 같기된다. 이는 그 어떤 client로도 blocking time을 초과할 수 없으며, 모든 client가 full server WCET에 한도를 사용하여야 한다. 우리의 모델은 좀 더 나은 유연성을 제공한다. 서버는 timeout exception을 사용하여 요청을 빨리 끝낼 수 있으며(aborting), 이는 clients들이 다른 클라이언트의 최대 한도 동안만 차단되고 이는 짧은 cleanup time을 의미한다.
요구시, helping schemes는 우리 모델에서 도입될 수 있다. (예를 들어 게이트 웨어 서버를 사용하여 요청이 들어올 시 우선도를 조정할 수 있음)    

# IMPLEMENTATION IN SEL4
## Objects
우리는 sel4 variably-sized scheduling context object(변동 크기 스케줄 객체) 타입을 추가한다. 이 최소 크기는 2^8 byte이다. 이는 64 또는 32 비트 프로세서에 각각 8 또는 10개의 replenishment를 제공한다. 이는 대부분 용도에 쓰일 수 있지만 더 많은 replenishments가 필요한 경우 크기를 키워서 요구사항을 만족시킬 수 있다. sporadic replenishments는 정확히 언제 사용될지 명시하며 이는 16바이트로 인코딩 되어있다. SC는 한도의 주기를 포함하고 접근을 제공하는 프로세서 코어의 ID를 포함하고 있다. 또한 donation chain을 위해 적합한 소유자로 리턴하기 위한 포인터를 포함한다. 
다른 sel4 객체 처럼 SC는 가용한 메모리를 사용하여(untype) SC 타입으로 재타입하여 만들어지며 0 한도를 보유한 SC들의 array가 만들어 진다. 이는 그 누구나 capability를 가지고 있다면 untyped에서 SC를 만들수 있다. 한도를 0이외의 값으로 조정하는 건 admission control이며 이는 sched_control capability가 필요하다.
스케줄링은 thread control block(TCB)과 관련이 있는데, 이는 해당하는 스레드를 스케줄 가능케 한다.(SC에 한도가 있다고 가정할 시). SC는 notification 객체와 관련이 있는데, 이는 이진 semaphores로 구성된 작은 array이다. 


Resume(재시작 객체) objects는 KeyKOS를 따라 모델링 되었으며, 이는 새로운 객체 타입이며 기본 seL4의 "reply capability(응답 기능)"을 일반화한다. 이 기능은 가상 객체이며, kernel on-the-fly in seL4's RPC-style call() 작업이며, 
이는 종점에 메세지를 보내며 답장을 차단한다. 매세지의 수신자(서버)의 답장 기능을 기능 공간에 "답장 slot"으로 수신한다. 서버는 그 기능을 사용함으로써 답장한다. 재시작 객체는 이러한 마법을 적극적으로  응답 채널을 표현함으로써 제거한다. 또한
이는 더 효율적으로 stateful 서버를 지원하며 이러한 서버는 여러 클라이언트 세션을 동시에 다룰 수 있다.
SC 기부로 인해 우리는 좀 더 bookkeeping이 더 필요한데, 이는 기부된 SC가 정당한 주인에게 다시 돌려주어야 하기 때문이며, 설사 서버가 다른 수동적 서버나 서바 작업 시간이 너무 길어 
여러 요청을 동시에 다루는 경우도 포합된다(파일 서버)
재시작 객체는 세 개의 포인터로 이루어져 있는데, 첫째로 SC를 소유하는 active thread, 두번째는 immediate caller's 재시작 객체, 세번째로는 chain에 존재하는 다음 재시작 객체이다.
TCB(스레드 컨트롤 블럭)객체에서 레거시 시간조각을 scCap으로 대체한다. 여기서는 다섯개의 변수가 추가된다. a timeout-handler capability, a Resume object pointer, an MCP value, and some
bookkeeping data. seL4 객체 크기는 2배씩 증가해야해서 충분한 공간이 생겨 데이터를 추가하더라도 TCB의 크기는 증가하지 않았다.
MCP(maximum controlled priority)의 경우, 초기 L4 커널에 사용된 개념을 부활시킨다. 이는 가볍고 제한된 커널 우선도 조작을 지원하며, 이는 사용자 레벨 스레드 패키지를 조작하는데 유용하다.
TCB의 MCP (A) 의 우선도를 설정할 때 caller는 TCB (B)로 capability를 제시해야 한다. caller는 우선도를 정하거나 A의 MCP를 B의 MCP의 값으로 설정이 가능하다.
일반적인 시스템에서는 대부분 스레드가 MCP 값이 0이거나 TCB의 capability 중 높은 MCP 것에는 접근이 안되며, 이는 그 어떤 스레드의 우선도도 설정할 수 없음을 의미한다.
MCP는 분명하게 지원된 TCB로부터 가져오고(caller 말고)이는 confused deputy problem을 피하기 위함이다.
우리는 TCB에 작동하는 함수를 추가하여 MCP를 관리하고 SC를 configure 할 수 있도록 한다. SC에는 5개의 함수(매서드)가 있는데, 이는 객체 binding / unbinding과 SC에 접근을 가진 스레드가 분명하게 yield(양보)할 수 있게 하여 해당 SC의 우선도를 사용하여 스케줄러 큐 앞쪽으로 이동시킬 수 있다.
이는 사용자 레벨 스케줄링이다. 이에 관련되서 figure 3에서 볼수 있다.

SchedContext_Bind(cap_t sc, cap_t obj); 해당 SC에 TCB또는 Notification을 Bind한다.

SchedContext_Unbind(cap_tc sc)l 해당 SC에서 모든 객체를 Unbind한다.

SchedContext_UnbindObject(cap_t sc, cap_t obj); 해당 SC에서 특정 객체를 Unbind한다.

SchedContext_Consumed(cap_t sc); 마지막 타임아웃에서 fault / consumed / yieldTo된 시간을 리턴한다.

SchedContext_YieldTo(cap_t sc); 해당 SC에 TCB bound를 해당 우선도 큐에 배치하여 소비량을 리턴한다.

SchedContext_Configure(cap_t sc, uint64_t budget, uint64_t period, word_t extra_refills, word_t badge); Scheduling context를 설정한다.

TCB_SetTimeoutEndpoint(capt_t tcb, cap_t ep); TCB의 timeout fault handler를 설정한다.

TCB_SetSchedParams(cap_t tcb, capt_t auth_tcb, word_t mcp, word_t priority, cap_t sc); TCP의 MCB (auth_tcb로부터 권한을 부여받은)의 우선도를 설정하여 SC에 bind한다. 

## System calls
재시작 객체를 사용하기 위해서는 IPC 시스템-콜 API에 변화가 필요하다. client-style call() 함수는 변화하지 않지만, 동일한 수준의 서버쪽 함수인 
ReplyRecv(또는 구버전 기준 ReplyWait)는 그 전 요청에 답장하고 다음 요청을 차단한다. 그래서 분명하게 재시작 capability를 표현해야 한다.
송신 단계에서는, capability가 client를 인식하고 SC를 리턴하는데(적절하다면), 수신단계에서는 새로운 값으로 구성된다.
새로운 API는 stateful server implementation을 좀 더 효율적으로 만든다. 바닐라 seL4에서는 서버가 최소한 추가로 2개의 시스템 콜을 사용하여 reply cap를 아끼고 나중에 magic slot으로 이동하여 magic을 제거하고 추가적인 시스템 콜의 필요성을 제거한다.
atomically Notification를 신호하고 메세지를 차단하기 위해서는 2개의 메서드가 있다. 이는 수동 서버의 초기화를 위해 필요하다. 새로운 API 매서드는 figure 4에서 확인할 수 있다.

seL4_Recv(cap_t src, word_t *badge, cap_t reply); 메세지를 기다리면서, 수신 시 객체의 badge를 저장하고 답장을 통해 caller를 차단한다.

seL4_ReplyRecv(cap_t src, word_t msg_info, word_t *badge, cap_t reply); 위와 같지만 답장을 먼저 실행한다.

seL4_NBSendRecv(cap_t dest, word_t msg_info, cap_t src, word_t *badge, cap_t reply); 위와 같지만 답장말고 dest를 실행 한다. 

seL4_NBSendWait(cap_t cap, word_t msg_info, cap_t src, word_t *badge); 위와 같이 답장은 없으며 기부는 불가능하다.

seL4_Wait(cap_t src, word_t *badge); 수신자이며 기부는 불가능 하다.


## Scheduling algorithm
우리는 seL4를 tick-based에서 tickless 커널로 전환하는데, 이는 preemption을 줄이고 스케쥴러의 정확도를 높이기 위함이다. seL4는 non-preemptible하다. 이는 explicit preemption points가 긴 작업을 의미한다.
이는 tickless 커널 디자인이 non-trivial하는데, 이는 preemption interrupt가 커널 자체를 interrupt할 수 없기 때문이다.
seL4에는 ready queue(준비 큐)가 있는데, 여기서 만족하는 invariant는 모든 작동하는 스레드를 포함지만 현재 실행하고 있는 스레드는 제외한다.
2개의 레벨의 bitfield의 occupied 우선도는 O(1) 접근을 보장한다. 여기에 우리는 release queue(릴리즈 큐)를 추가하는데, 이곳에는 커널이 한도가 소진된 스레드를 queue시키는 곳이다.
이는 이미 존재하는 ready queue의 invariant를 보장하면서도 release queue에는 한도가 있었다만 작동할 수 있는 모든 스레드를 포함한다. 릴리즈 큐는 다음 빠른 보충 시간에 따라 스레드를 정렬한다.
커널이 스레드를 스케줄할 때, 스레드의 SC의 한도 만료에 또는 릴리즈 큐 헤드의 다음 wake-up time 중 더 빠른 것에 타이머를 설정한다.
만약 SC 스위치가 일어난다면, 이는 타이머가 작동하거나 스레드가 SC transfer없이 차단하기 때문이며, 소비된 시간은 sporadic server algorithm에 따라 차감되며
축적된 시간은 업데이트 된다.
커널 entry에서 커널은 현재 시간을 업데이트하며 마지막 엔트리로부터의 시간을 저장한다. 다음으로는 스레드가 커널 작업을 수행하기 위해 충분한 한도를 가지고 있는지 확인한다.
그렇지 않다면, 커널은 타이머가 작동했다고 가정하여 한도를 리셋하고 해당 스레드를 릴리즈 큐로 추가시킨다.
이는 새로운 invariant를 생성하는데, 스케줄링 큐에 있는 그 어떤 스레드라도 커널에서 나오기 위해서는 충분한 한도가 필요하다.
이는 스케줄러 정확도를 커널의 WCET보다 두배 더 높게 만든다. 이 invariant는 반드시 필요한데, 이는 커널 디자인을 간단하게 만들고 WCET를 감소시키기 때문이다.
만약 스레드에 시간이 부족하다면 timeout exception을 유발해야할 필요성이 있는데, 이는 timeout handler에 IPC를 전달 해야한다.
모모든 스레드가 레디 큐나 종점 큐에 있도록 요구함으로써, 스레드가 살아나려면 충분한 한도가 필요하며 이는 커널의 wakeup path에 timeout exception을 사용해야할 이유를 없애준다.
스레드는 scheduling context가 변경될때만 charged되며, 이는 타이머를 재설계하는것을 피하게하는데 대부분 플랫폼에서 비싸기 떄문이다. 만약 SC에 변화가 없다면, 타임스탬프는 저장되어있는 소비값을 차감하여 롤백된다. 

![](/images/Scc/5.png)

## Scheduling context donation
Donation(기부)는 IPC나 Notification wait의 타겟 스레드가 scheduling context가 없을이 발생한다. SC는 코어에 접근할 수 있는 권한을 의미하므로, donation은 intra-core(코어 간) 발생한다. 만약 수동 서버가 다른 코어에서 실행되었다면, execution context는 invocation 시 클라이언트 코어에 이동된다. 이는 모든 스케줄 분석에 포함되어야할 overhead 이다.
우리는 resume capabilities를 사용하여 scheduling donation chains를 추적하고, 이를 다음 그림이 설명한다. S라는 수동 서버가 종점 E를 차단하고 client A로부터 요청을 수락한다. S는 수동이기에, $SC_{A}$는 S에 기부되며 이는 IPC rendevous에서 일어난다. 추가적으로 커널은 recv에서 S가 제공한 Resume object위에서 A를 차단한다. A는 서버가 Resume object에 응답할때까지 차단되는데, 이 때 SC가 A로 리턴된다. SC 기부에는 제한이 없으며, 이 과정은 무한정 진행될 수 있다.
만약 S가 A를 대신하여 작동할 경우, scheduling context $SC_{A}$는 $R_{A}$를 가르키고, 이는 IPC call chain에서 추가적인 resume object를 가르킬 수 있다. timeout handler의 경우 스레드 특성을 가지며 A는 없고 S는 한개를 가지고 있다. $SC_{A}#는 서버가 요청을 처리하는 동안 만료된다. 

![](/images/Scc/6.png)

![](/images/Scc/7.png)



















